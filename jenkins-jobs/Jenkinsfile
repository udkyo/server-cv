/**
 * Jenkinsfile CV Pipeline
 *
 * Defines a pipeline to be used in Jenkins jobs. Re-implements
 * single-project-gerrit and single-project-clang_analyzer.
 * This pipline supports linux, ThreadSanitizer, AddressSanitizer &
 * UndefinedBehaviourSanitizer, and clang_analyzer (static analysis) jobs.
 * [Documentation](README.md)
 */

import hudson.Util


// When true, jobs using this Jenkinsfile will report "informational" votes
// and will not cause an overall -1 Verification if they fail.
// This is useful when forking to testing new jobs or changes to the pipeline.
//
// By default is true if the job name contains the string "silent". Note
// That anything after the second '.' in JOB_NAME is otherwise ignored, so
// you can make a job silent by renaming it something like
// 'kv_engine.linux.silent'

SILENT = env.JOB_NAME.contains("silent")

WINDOWS_NODE_LABEL = "msvc2022"
LINUX_NODE_LABEL = "linux && large"
MACOS_NODE_LABEL = "ventura"

pipeline {
    options {
        buildDiscarder(logRotator(daysToKeepStr: '30', numToKeepStr: '',
                                  artifactDaysToKeepStr: '2',
                                  artifactNumToKeepStr: ''))
        timestamps()
    }
    agent { label getNodeLabel() }
    stages {
        stage("Prepare Environment"){
            steps {
                script {
                    // Configure Gerrit Trigger
                    properties([pipelineTriggers([gerrit(silentMode: SILENT,
                        customUrl: '',
                        serverName: 'review.couchbase.org',
                        silentStartMode: true,
                        gerritProjects: [[branches: [[compareType: 'PLAIN',
                                                      pattern: env.BRANCH_NAME]],
                                          compareType: 'PLAIN',
                                          disableStrictForbiddenFileVerification: false,
                                          pattern: getProjectName()]],
                        triggerOnEvents: [patchsetCreated(excludeDrafts: true,
                                                          excludeNoCodeChange: true,
                                                          excludeTrivialRebase: false,
                                                          excludeWipState: true),
                                          draftPublished(),
                                          wipStateChanged()])])])
                }

                // look for config files which specify env vars
                loadEnvFiles()

                // Common script run by various Jenkins commit-validation builds.
                //
                // Checks out all the gerrit changes with change-ids matching
                // $GERRIT_PATCHSET_REVISION in an appropriate branch for the current
                // manifest from Gerrit server GERRIT_HOST:GERRIT_PORT, compiles and then
                // runs unit tests for GERRIT_PROJECT (if applicable).
                script {
                    requiredEnvVars = ['GERRIT_HOST',
                                       'GERRIT_PORT',
                                       'GERRIT_PROJECT',
                                       'GERRIT_PATCHSET_REVISION',
                                       'GERRIT_REFSPEC',
                                       'GERRIT_CHANGE_ID']

                    for (var in requiredEnvVars) {
                        if (!env.getProperty(var)){
                            error "Required environment variable '${var}' not set."
                        }
                    }

                    // Optional env vars - how many jobs to run in parallel by default?
                    // The smallest (oldest) builders are ~4 core, so if PARALLELISM
                    // hasn't otherwise been set for the node / job default to
                    // 6 (4 CPU cores + 2, same calculation as Ninja).
                    env.PARALLELISM = env.PARALLELISM ? env.PARALLELISM : 6

                    // Set default TEST_PARALLELISM to half of PARALLELISM -
                    // many of our tests are actually multi-threaded
                    //(unlike the compiler) and hence running #CPUs tests in
                    // parallel (each with multiple threads) can overload the CV machines
                    // and cause test timeouts.
                    env.TEST_PARALLELISM = env.TEST_PARALLELISM
                        ? env.TEST_PARALLELISM
                        : ((env.PARALLELISM as Integer) / 2)

                    env.CBBUILD_DIR = "${pwd()}/cbbuild"

                    // default CMAKE_ARGS to an empty string if unset
                    env.CMAKE_ARGS = env.CMAKE_ARGS ?: ""

                    if (getJobName() != "windows") {
                        env.CMAKE_ARGS="-DCMAKE_BUILD_TYPE=DebugOptimized ${CMAKE_ARGS}"
                    }

                    if (env.ENABLE_CODE_COVERAGE) {
                       env.CMAKE_ARGS="${CMAKE_ARGS} -DCB_CODE_COVERAGE=ON"
                    }
                    if (env.ENABLE_THREADSANITIZER) {
                       env.CMAKE_ARGS="${CMAKE_ARGS} -DCB_THREADSANITIZER=ON"
                    }
                    if (env.ENABLE_ADDRESSSANITIZER) {
                       env.CMAKE_ARGS="${CMAKE_ARGS} -DCB_ADDRESSSANITIZER=${ENABLE_ADDRESSSANITIZER}"
                    }
                    if (env.ENABLE_UNDEFINEDSANITIZER) {
                       env.CMAKE_ARGS="${CMAKE_ARGS} -DCB_UNDEFINEDSANITIZER=${ENABLE_UNDEFINEDSANITIZER}"
                    }
                    if (env.ENABLE_CBDEPS_TESTING) {
                       env.CMAKE_ARGS="${CMAKE_ARGS} -DCB_DOWNLOAD_DEPS_REPO="+
                       "http://latestbuilds.service.couchbase.com/builds/releases/cbdeps"
                    }
                    // Constrain link parallelism to half of the compile
                    // parallelism given that linking is typically much more RAM
                    // hungry than compilation, and we have seen the build get
                    // OOM-killed on machines which have many cores but lower
                    // RAM (e.g. 16 cores, 16 GB RAM).
                    if (env.PARALLELISM) {
                       link_parallelism = ((env.PARALLELISM as Integer) / 2)
                       env.CMAKE_ARGS="${CMAKE_ARGS} -DCB_PARALLEL_LINK_JOBS=${link_parallelism}"
                    }

                    env.CMAKE_GENERATOR = env.CMAKE_GENERATOR ? env.CMAKE_GENERATOR : "Ninja"

                    if (env.GERRIT_PROJECT == "ns_server") {
                        env.BUILD_DIR="${GERRIT_PROJECT}/build"
                    }
                    else if (env.GOPROJECT) {
                        env.BUILD_DIR="build/goproj/src/github.com/couchbase/${GERRIT_PROJECT}"
                    } else {
                        env.BUILD_DIR="build/${GERRIT_PROJECT}"
                    }
                }

                sh 'ulimit -a'
                echo ""
                sh 'env | grep -iv password | grep -iv passwd | sort'
            }
        }

        stage("Checkout Repo"){
            steps {
                script {
                    // Manually tracking run time as
                    // currentBuild.durationString includes time spent
                    // waiting for a node
                    env.startTime = System.currentTimeMillis()
                    // Print the Job Type to ensure we've selected the correct Job
                    println('Job Type : ' + getJobType())
                }
                checkout([$class: 'RepoScm',
                    currentBranch: true,

                    // To use multiple jobs in the repo sync (equivalent to -j ) use
                    // jobs: PARALLELISM,
                    // However this may not currently work on windows

                    manifestFile: "${getManifestFileName()}",
                    manifestGroup: getManifestGroup(),
                    manifestRepositoryUrl: 'https://github.com/couchbase/manifest.git',
                    quiet: true,
                    // GitHub has disabled raw git:// protocol which is the
                    // default for repo to perform it's auto-update check.
                    // Override to use https:
                    repoUrl: 'https://github.com/couchbasedeps/git-repo',
                    resetFirst: false])

                script {
                    def response = httpRequest url: getPatchViaGerritURL(), responseHandle: 'NONE', outputFile: 'patch_via_gerrit'
                }

                sh 'chmod u+x patch_via_gerrit'
                sh './patch_via_gerrit -c ${HOME}/.ssh/patch_via_gerrit.ini -g $GERRIT_CHANGE_ID -s $WORKSPACE -C'
            }
        }

        stage("Clean"){
            steps {
                sh '(cd ns_server && git clean -xfdq) || true'
                sh 'cmake --build build --target clean || true'
                // Remove CMake's cache and previously generated
                // CMakeFiles (detected compiler, generator etc).
                // This helps to avoid issues where previously cached
                // values need to be regenerated by newer code.
                sh 'rm -fr build/CMakeCache.txt build/CMakeFiles'
                sh "find build/${getProjectName()}/Testing -name Test.xml -delete || true"
                // Remove any previous ASan / TSan etc log files so warning
                // counts are accurate.
                sh "find build/${getProjectName()} -name sanitizers.log.* -delete || true"

                // Zero ccache stats, so we can measure how much space this build is
                // consuming.
                sh 'ccache -z'

                // Wipe out any core files left from a previous run.
                sh ' rm -f /tmp/core.*'

                script {
                    if (env.ENABLE_CBDEPS_TESTING) {
                        sh 'rm -rf ~/.cbdepscache'
                        sh 'rm -rf build/tlm/deps'
                    }
                }
            }
        }

        stage("Configure"){
            when {
                // Do not run this build stage if this is a static analysis job
                // - the "Static Analysis" stage will do the required work.
                expression { getJobType() != 'clang_analyzer' }
            }

            steps {
                // If we've checked out a specific version of the tlm project
                // then we'll need to bring our new CMakeLists.txt in manually
                sh 'cp -f tlm/CMakeLists.txt CMakeLists.txt'
                sh 'cp -f tlm/third-party-CMakeLists.txt third_party/CMakeLists.txt'
                sh 'mkdir -p build'
                sh 'cd build && cmake -G ${CMAKE_GENERATOR} ${CMAKE_ARGS} ..'
            }
        }

        stage("Build"){
            when {
                // Do not run this build stage if this is a static analysis job
                // - the "Static Analysis" stage will do the required work.
                expression { getJobType() != 'clang_analyzer' }
            }
            steps {
                sh 'cmake --build build --parallel ${PARALLELISM} --target everything --target install'
                sh 'ccache -s'
            }
        }

        stage("Test"){
            when {
                expression { getJobType() != 'clang_analyzer' }
            }
            steps {
                script {
                    if (shouldRunUnitTests()) {
                        dir(env.BUILD_DIR) {
                            if (env.ENABLE_CODE_COVERAGE) {
                                // Reset code coverage counters (note optional hence the || true).
                                sh 'make ${GERRIT_PROJECT}-coverage-zero-counters || true'
                            }

                            // -j${TEST_PARALLELISM} : Run tests in parallel.
                            // -T Test   : Generate XML output file of test results.
                            sh 'ctest -j${TEST_PARALLELISM} --output-on-failure \
                                --no-compress-output -T Test ${CTEST_ARGS}'

                            // Generate code coverage report in XML format for Jenkins plugin.
                            if (env.ENABLE_CODE_COVERAGE) {
                                sh 'make ${GERRIT_PROJECT}-coverage-report-xml || true'
                            }
                        }
                    } else {
                        echo """
                        ============================================
                        ===  ${GERRIT_PROJECT} is not a Go project. It also doesn't have a CTestTestfile.cmake.
                        ===  Skipping Unit tests.
                        ============================================""".stripIndent()
                    }

                    if (env.RUN_SIMPLE_TEST) {
                        sh 'make -C testrunner simple-test VERBOSE=1'
                    }
                }
            }
        }
        stage("Static Analysis"){
            when {
                expression { getJobType() == 'clang_analyzer' }
            }
            steps {
                script {
                    env.SCAN_BUILD_PATH = sh(returnStdout: true, script: 'which $SCAN_BUILD || which scan-build-3.6')

                    // Can't use ccache with clang analyzer - see
                    // https://llvm.org/bugs/show_bug.cgi?id=25851
                    env.CMAKE_ARGS="${CMAKE_ARGS} -DCOUCHBASE_DISABLE_CCACHE=1"

                    env.REPORT_DIR="${pwd()}/clangScanBuildReports"
                    def absCC = sh(returnStdout: true, script: 'which $CC')
                    env.SCAN_BUILD_ARGS="--use-analyzer=${absCC} -o ${REPORT_DIR}"
                }
                // If we've checked out a specific version of the TLM
                // then we'll need to bring our new CMakeLists.txt in manually
                sh 'cp -f tlm/CMakeLists.txt ./CMakeLists.txt'

                // We only want to build the Gerrit project under test,
                // as we only want issues which are related to that project,
                // and there doesn't appear to be a way to cull the results to a specific
                // pattern / sub-directory.
                // Therefore run cmake to generate all the makefiles, then just
                // run make in the specific sub-directory.
                sh 'mkdir -p build'
                dir('build') {
                    sh '$SCAN_BUILD_PATH ${SCAN_BUILD_ARGS} \
                             cmake .. ${CMAKE_ARGS}'

                    // The CMake configure step leaves an analyzer output run which
                    // confuses the Jenkins scan-build plugin. Clean out the directory
                    // before starting the actual build so we end up with just one report.
                    sh 'rm -fr ${REPORT_DIR}/*'

                    sh '$SCAN_BUILD_PATH ${SCAN_BUILD_ARGS} \
                             make -C ${GERRIT_PROJECT} -j${PARALLELISM}'
                 }
            }
        }
    }
    post {
        always {
            script {
                if (shouldRunUnitTests()) {
                    xunit(testTimeMargin: '3000', thresholdMode: 1,
                          thresholds: [failed(failureThreshold: '0'),
                                       skipped(failureThreshold: '0')],
                          tools: [CTest(deleteOutputFiles: true,
                                        failIfNotNew: true,
                                        pattern: "build/${getProjectName()}/Testing/**/Test.xml",
                                        skipNoTestFiles: false,
                                        stopProcessingIfError: true)])
                }

                recordIssues(enabledForFailure: true,
                             tools: [groovyScript(parserId: 'AddressSanitizer',
                                                  pattern: '**/sanitizers.log.*'),
                                     groovyScript(parserId: 'LeakSanitizer',
                                                  pattern: '**/sanitizers.log.*'),
                                     groovyScript(parserId: 'UndefinedBehaviourSanitizer',
                                                  pattern: '**/sanitizers.log.*')],
                             qualityGates: [[threshold: 1,
                                             type: 'TOTAL',
                                             unstable: false]])

                // Check for core files - if present then archive them and the
                // executable they are from (for post-mortem) and fail the build.
                def statusCode = sh (returnStatus:true,
                    script:'''#! /bin/bash -x
                    shopt -s nullglob
                    ${CBBUILD_DIR}/scripts/jenkins/commit_validation/archive_core_files.sh archived_core_dumps /tmp/core.*
                    rm -f /tmp/core.*''')

                if (statusCode != 0) {
                    // fail the build if core files were found
                    currentBuild.result = 'FAILURE'
                }
            }
            archiveArtifacts(allowEmptyArchive: true,
                             artifacts: 'archived_core_dumps.tar.bz2,**/sanitizers.log.*')
            reportWarnings()
            cleanWs cleanWhenFailure: false,
                    cleanWhenNotBuilt: false,
                    cleanWhenUnstable: false,
                    notFailBuild: true,
                    deleteDirs: true,
                    patterns: [[pattern: 'build', type: 'INCLUDE'],
                               [pattern: 'install', type: 'INCLUDE'],
                               [pattern: '**/CTestCostData.txt', type: 'EXCLUDE']]
        }
        // success {
        //     submitGerritVerifyStatus(1)
        // }
        // failure {
        //     submitGerritVerifyStatus(-1)
        // }
    }
}


def getJobType() {
    // e.g., kv_engine.ASan-UBSan.some_testing_change/master
    // we want ASan-UBSan
    return getJobName().tokenize(".")[1]
}

def getJobName() {
    // e.g., kv_engine.ASan-UBSan.some_testing_change/master
    // we want kv_engine.ASan-UBSan.some_testing_change
    def jobNamePart = env.JOB_NAME.tokenize("/")[0]
    return jobNamePart.replaceFirst(/^testing-/, "")
}

def getProjectName() {
    // e.g., kv_engine.ASan-UBSan.some_testing_change/master
    // we want kv_engine
    return getJobName().tokenize(".")[0]
}

def getNodeLabel() {
    def osLabel = ""
    switch(getJobType()) {
        case "windows":
            osLabel = WINDOWS_NODE_LABEL
            break;
        case "macos":
            osLabel = MACOS_NODE_LABEL
            break;
        case ~/aarch64-linux.*/:
            osLabel = "aarch64 && linux"
            break;
        default:
            osLabel = LINUX_NODE_LABEL
            break;
    }
    return "${osLabel} && testing"
}

def getPatchViaGerritURL() {
    def base = "https://packages.couchbase.com/patch_via_gerrit/patch_via_gerrit-"
    switch(getJobType()) {
        case "windows":
            return base + "windows.exe"
        case "macos":
            return base + "darwin"
        case "aarch64-linux":
            return base + "linux-aarch64"
        default:
            return base + "linux-x86_64"
    }
}

def getManifestFileName() {
    if (env.BRANCH_NAME == 'master') {
        return 'branch-master.xml'
    } else {
        return "couchbase-server/${env.BRANCH_NAME}.xml"
    }
}

def getManifestGroup() {
    // For projects part of kv_engine (kv_engine, platform, couchstore, ...)
    // we don't want to checkout _all_ repos as that is unnecessary. However
    // we also support CV for other projects (e.g. tlm, sigar) where we want to
    // build as EE and hence need 'enterprise' repos.
    if (["tlm", "sigar"].contains(env.GERRIT_PROJECT)) {
        return 'default,build,enterprise'
    } else {
        return 'build,kv,kv_ee'
    }
}

/**
 * Should unit tests be run (and results reported)?
 * Skip for clang-analyzer (all work is performed at compile time),
 * otherwise run if unit tests are defined for this project.
 *
 * Note that we deliberately don't run unit tests for "tlm" project - while
 * this is logically the top-level build and compiles everything, we don't
 * want to run unit tests for all projects as:
 *   a) that would take a long time for a CV job
 *   b) it would be testing other projects which may not have stable unit
 *      tests.
 * As such we take advantage of the fact that the tlm 'project' directory
 * doesn't have any ctest tests defined ("${BUILD_DIR}/CTestTestfile.cmake
 * doesn't exist) to skip here.
 */
def shouldRunUnitTests() {
    return (getJobType() != 'clang_analyzer') &&
        (env.GOPROJECT || fileExists("${BUILD_DIR}/CTestTestfile.cmake"))
}

/**
 * Submit compiler warnings to Jenkins
 *
 * Equivalent of the post-build "Scan for compiler warnings" action.
 *
 */
def reportWarnings() {
    def parser
    def failedTotal = "${env.WARNING_THRESHOLD ? env.WARNING_THRESHOLD : 0}"

    if (getJobName() == 'clang_analyzer') {
        parser = 'Clang (LLVM based)'
    } else {
        parser = 'GNU Make + GNU C Compiler (gcc)'
    }

    warnings(canComputeNew: false, canResolveRelativePaths: false,
             categoriesPattern: '', consoleParsers: [[parserName: parser]],
             defaultEncoding: '', excludePattern: '',
             failedTotalAll: failedTotal, healthy: '',
             includePattern: '.*[/\\\\]' + getProjectName() + '[/\\\\].*',
             messagesPattern: '', unHealthy: '')
}

/**
 * Report vote to Gerrit verify-status plugin.
 *
 * Adds the job result to the verify-status sidebar in the Gerrit patch
 * view. This is hacky - the Jenkins plugin that does this for normal jobs
 * does not appear to have been updated to be used from Pipelines.
 * If a way of using the proper plugin is found, or it is updated, it should
 * definitely replace this.
 */
def submitGerritVerifyStatus(value) {
    if (env.GERRIT_PATCHSET_REVISION != null) {
        // Directly report the verify status to Gerrit
        // The jenkins plugin which reports to the verify-status sidebar does not seem to be up to date
        // TODO: Investigate the HTTP API for greater portability (e.g., windows!)

        def jobName = getJobName()
        def url = "http://cv.jenkins.couchbase.com/job/${getJobName()}/job/${env.BRANCH_NAME}/${BUILD_NUMBER}/"
        def startTimeMs

        if (env.startTime != null) {
            startTimeMs = env.startTime as Long
        } else {
            // if something went wrong we might not have stored the start time
            // use the Jenkins provided value, even though this includes time spent
            // waiting for a node
            startTimeMs = currentBuild.startTimeInMillis as Long
        }

        def duration = "${Util.getTimeSpanString(System.currentTimeMillis() - startTimeMs)}"

        sh """ssh -p ${env.GERRIT_PORT} buildbot@${env.GERRIT_HOST} \
        -o "UserKnownHostsFile=/dev/null" -o "StrictHostKeyChecking=no" \
        verify-status save --verification \
        "'name=${jobName}|value=${value}|url=${url}|abstain=${SILENT}|reporter=buildbot|duration=${duration}'" \
        ${GERRIT_PATCHSET_REVISION}"""
    }
}


/**
 * Read environment config files
 *
 * Loads environment variables defined in jenkins-jobs/config/*.groovy files
 * into the environment passed to shell steps.
 */
def loadEnvFiles() {
    def jobName = getJobType()
    // load env vars from groovy files in the config dir, in the order:
    // 1. job-common config (e.g. config for all ASan jobs)
    // 2. project-common config (e.g. config for all kv_engine jobs)
    // 3. job and project speific (e.g. config for ASan-kv_engine)
    def common_job = "jenkins-jobs/config/common/${jobName}.groovy"
    def common_project = "jenkins-jobs/config/${getProjectName()}/common.groovy"
    def project_specific = "jenkins-jobs/config/${getProjectName()}/${jobName}.groovy"
    for (fileName in [common_job, common_project, project_specific]) {
        echo "Checking for config file ${fileName}"
        if (fileExists(fileName)) {
            def closure = load fileName
            addToEnv(closure)
            echo "Loaded env from ${fileName}"
        }
    }
}

/**
 * Execute a closure with delegate set to `env`
 *
 * Helper method - used to execute closures defined in config files
 * to add all defined variables to the `env` global.
 */
def addToEnv(closure) {
    // The config files define a groovy closure.
    // Setting the delegate to env and specifying DELEGATE_FIRST
    // means variables assigned inside the closure are
    // assigned "inside" env's scope - making them
    // available as env vars in the same way
    // env.FOO="BAR" does.
    closure.resolveStrategy = Closure.DELEGATE_FIRST
    closure.delegate = env
    closure()
}
